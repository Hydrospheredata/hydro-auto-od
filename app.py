import datetime
import glob
import json
import os
import sys
import tempfile
import logging
from enum import Enum
from multiprocessing import Process
from shutil import copytree
from time import sleep
from typing import List
from logging.config import fileConfig

import git
import joblib
import pandas as pd
from flask import Flask, jsonify, request, Response
from flask_cors import CORS
from hydro_serving_grpc.contract import ModelField, ModelContract
from hydrosdk.cluster import Cluster
from hydrosdk.image import DockerImage
from hydrosdk.model import Model, LocalModel, UploadResponse
from hydrosdk.monitoring import TresholdCmpOp, MetricSpecConfig, MetricSpec
from jsonschema import Draft7Validator
from pymongo import MongoClient
from pyod.models.hbos import HBOS
from s3fs import S3FileSystem
from waitress import serve
import sseclient
import requests

from tabular_od_methods import TabularOD
from utils import get_monitoring_signature_from_monitored_signature, DTYPE_TO_NAMES

fileConfig("logging_config.ini")

with open("version") as f:
    VERSION = f.read().strip()
    repo = git.Repo(".")
    BUILDINFO = {
        "version": VERSION,
        "gitHeadCommit": repo.active_branch.commit.hexsha,
        "gitCurrentBranch": repo.active_branch.name,
        "pythonVersion": sys.version
    }

with open("./schemas/auto_metric.json") as f:
    auto_metric_request_json_validator = Draft7Validator(json.load(f))


class AutoODMethodStatuses(Enum):
    PENDING = 0
    STARTED = 1
    SELECTING_MODEL = 2
    SELECTING_PARAMETERS = 3
    DEPLOYING = 4
    SUCCESS = 5
    FAILED = 6
    NOT_SUPPORTED = 7


def get_mongo_client():
    return MongoClient(host=MONGO_URL, port=MONGO_PORT,
                       username=MONGO_USER, password=MONGO_PASS,
                       authSource=MONGO_AUTH_DB)


HS_CLUSTER_ADDRESS = os.getenv("HS_CLUSTER_ADDRESS", "http://localhost")

MONGO_URL = os.getenv("MONGO_URL", "localhost")
MONGO_PORT = int(os.getenv("MONGO_PORT", 27017))
MONGO_AUTH_DB = os.getenv("MONGO_AUTH_DB", "admin")
MONGO_USER = os.getenv("MONGO_USER")
MONGO_PASS = os.getenv("MONGO_PASS")
AUTO_OD_DB_NAME = os.getenv("AUTO_OD_DB_NAME", "auto_od")
S3_ENDPOINT = os.getenv("S3_ENDPOINT")
DEBUG_ENV = bool(os.getenv("DEBUG", True))

hs_cluster = Cluster(HS_CLUSTER_ADDRESS)
mongo_client = get_mongo_client()
db = mongo_client[AUTO_OD_DB_NAME]

app = Flask(__name__)
CORS(app)


@app.route("/", methods=['GET'])
def hello():
    return "Hi! I am auto_ad service"


@app.route("/buildinfo", methods=['GET'])
def buildinfo():
    """
    Return build information - Python Version, build commit and service version
    :return:
    """
    return jsonify(BUILDINFO)


@app.route('/auto_metric', methods=['GET'])
def status():
    """
    # Checks status of training job in mongodb
    :return:
    """
    expected_args = {"monitored_model_version_id"}
    if set(request.args.keys()) != expected_args:
        return jsonify({"message": f"Expected args: {expected_args}. Provided args: {set(request.args.keys())}"}), 400

    model_version_id: int = int(request.args['monitored_model_version_id'])

    model_status = db.model_statuses.find_one({'monitored_model_version_id': model_version_id})

    if not model_status:
        return jsonify({"state": AutoODMethodStatuses.PENDING.name,
                        "description": "Training job for this model version was never requested."})
    else:
        return jsonify({"state": model_status['state'],
                        "description": model_status['description']})


@app.route('/auto_metric', methods=['POST'])
def launch():
    """
    Handles requests to create monitoring metrics for newly deployed model versions.
    Expected to be called from sonar.
    After checking that input parameters are valid, a new process will be created, and Response with HTTP code 202 will
    be returned from. Newly created process will update state in MongoDB as specified in Readme.MD and will train outlier detection model,
    deploy it, and attach to monitored model.
    :return:
    """

    job_config = request.get_json()

    if not auto_metric_request_json_validator.is_valid(job_config):
        error_message = "\n".join([error.message for error in auto_metric_request_json_validator.iter_errors(job_config)])
        return jsonify({"message": error_message}), 400

    training_data_path = job_config['training_data_path']

    monitored_model_version_id: int = job_config['monitored_model_version_id']

    code, message = process_auto_metric_request(training_data_path, monitored_model_version_id)
    return Response(status=code), jsonify({"message": message})


def process_auto_metric_request(training_data_path, monitored_model_version_id) -> (int, str):
    try:
        model_version = Model.find_by_id(hs_cluster, monitored_model_version_id)
    except ValueError:
        return 400, f"Model id={monitored_model_version_id} not found"

    if db.model_statuses.find_one({"monitored_model_version_id": monitored_model_version_id}):
        return 409, f"Training job already requested for model id={monitored_model_version_id}"

    if TabularOD.supports_signature(model_version.contract.predict):
        p = Process(target=train_and_deploy_monitoring_model,
                    args=(monitored_model_version_id, training_data_path))
        p.start()
        return 202, f"Started training job"
    else:
        model_status = db.model_statuses.insert_one({'monitored_model_version_id': monitored_model_version_id,
                                                     'training_data_path': training_data_path,
                                                     'state': AutoODMethodStatuses.NOT_AVAILABLE.name,
                                                     'description': "There are 0 supported fields in this model signature. "
                                                                    "To see how you can support AutoOD metric refer to the documentation"})

        return 200, f"Model state is {model_status['state']}, {model_status['description']}"


def train_and_deploy_monitoring_model(monitored_model_version_id, training_data_path):
    """
    This function:
    1. Downloads training data from S3 into pd.Dataframe
    2. Uses this training data to train HBOS outlier detection model
    3. Packs this model into temporary folder, and then into LocalModel
    4. Uploads this LocalModel to the cluster
    5. After this model finishes assemlby, attach it as a metric to the monitored model

    :param monitored_model_version_id:
    :param training_data_path: path pointing to s3
    :return:
    """
    # This method is intended to be used in another process,
    # so we need to create new MongoClient after fork
    mongo_client = get_mongo_client()
    db = mongo_client[AUTO_OD_DB_NAME]
    db.model_statuses.insert_one({'monitored_model_version_id': monitored_model_version_id,
                                  'training_data_path': training_data_path,
                                  'state': AutoODMethodStatuses.STARTED.name,
                                  'description': f"AutoOD training job started at {datetime.datetime.now()}"})

    logging.info("Getting monitored model (%d)", monitored_model_version_id)
    monitored_model = Model.find_by_id(hs_cluster, monitored_model_version_id)

    supported_input_fields = TabularOD.get_compatible_fields(monitored_model.contract.predict.inputs)
    supported_output_fields = TabularOD.get_compatible_fields(monitored_model.contract.predict.outputs)

    # FIXME. right now there are no outputs in file provided? to reproduce use
    # {"monitored_model_version_id": 83,
    #  "training_data_path": "s3://feature-lake/training-data/83/training_data901590018946752001483.csv"
    #  }

    supported_fields: List[ModelField] = supported_input_fields  # + supported_output_fields
    supported_fields_names: List[str] = [field.name for field in supported_fields]
    supported_fields_dtypes: List[str] = [field.dtype for field in supported_fields]

    logging.info("%s: Reading training data from %s", repr(monitored_model), training_data_path)
    if S3_ENDPOINT:
        s3 = S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT})
        training_data = pd.read_csv(s3.open(training_data_path, mode='rb'))[supported_fields_names]
    else:
        training_data = pd.read_csv(training_data_path)[supported_fields_names]

    # Train HBOS on training data from S3
    logging.info("%s: Training HBOS", repr(monitored_model))
    outlier_detector = HBOS()
    outlier_detector.fit(training_data)

    db.model_statuses.update_one({'monitored_model_version_id': monitored_model_version_id},
                                 {"$set": {'state': AutoODMethodStatuses.DEPLOYING.name,
                                           'description': "Uploading metric to the cluster"}})

    try:
        # Create temporary directory to copy monitoring model payload there and delete folder later after uploading it to the cluster
        with tempfile.TemporaryDirectory() as tmpdirname:
            monitoring_model_folder_path = f"{tmpdirname}/{monitored_model.name}v{monitored_model.version}_auto_metric"
            copytree("monitoring_model_template", monitoring_model_folder_path)
            joblib.dump(outlier_detector, f'{monitoring_model_folder_path}/outlier_detector.joblib')

            # Save names and dtypes of analysed model fields to use in handling new requests in func_main.py
            monitoring_model_config = {"field_names": supported_fields_names,
                                       "field_dtypes": [DTYPE_TO_NAMES[x] for x in supported_fields_dtypes]}
            with open(f"{monitoring_model_folder_path}/fields_config.json", "w+") as fields_config_file:
                json.dump(monitoring_model_config, fields_config_file)

            payload_filenames = [os.path.basename(path) for path in glob.glob(f"{monitoring_model_folder_path}/*")]

            monitoring_model_contract = ModelContract(
                predict=get_monitoring_signature_from_monitored_signature(monitored_model.contract.predict))
            auto_od_metric_name = monitored_model.name + "_metric"

            local_model = LocalModel(name=auto_od_metric_name,
                                     contract=monitoring_model_contract,
                                     payload=payload_filenames,
                                     path=monitoring_model_folder_path,
                                     metadata={
                                         "created_by": "hydro_auto_od",
                                         "training_data_path": training_data_path,
                                         "monitored_model_id": str(monitored_model_version_id),
                                         "monitored_model": repr(monitored_model)
                                     },
                                     install_command="pip install -r requirements.txt",
                                     runtime=DockerImage("hydrosphere/serving-runtime-python-3.6", "2.1.0", None))

            response = requests.get(HS_CLUSTER_ADDRESS + "/api/v2/events", stream=True)
            client = sseclient.SSEClient(response)
            logging.info("%s: Uploading monitoring model", repr(monitored_model))
            upload_response: UploadResponse = local_model._LocalModel__upload(hs_cluster)
            logging.info("%s: Waiting for monitoring model is built", repr(monitored_model))
            for event in client.events():
                logging.debug(event.data)
                if event.event == "ModelUpdate":
                    data = json.loads(event.data)
                    if data.get("id") == upload_response.model.id and data.get("status") != "Assembling":
                        break
    except Exception as e:
        logging.exception("%s: Error while uploading monitoring model", repr(monitored_model))
        db.model_statuses.update_one({'monitored_model_version_id': monitored_model_version_id},
                                     {"$set": {'state': AutoODMethodStatuses.FAILED.name,
                                               'description': f"Failed to pack & deploy monitoring model to a cluster - {str(e)}"}})
        return -1

    try:
        # Check that this model is found in the cluster
        monitoring_model = Model.find_by_id(hs_cluster, upload_response.model.id)

    except Exception as e:
        logging.exception("%s: Error while finding monitoring model", repr(monitored_model))
        db.model_statuses.update_one({'monitored_model_version_id': monitored_model_version_id},
                                     {"$set": {'state': AutoODMethodStatuses.FAILED.name,
                                               'description': f"Failed to find deployed monitoring model in a cluster - {str(e)}"}})

    # sleep(10)  # TODO make proper waiting for the end of the monitoring model assembly
    try:
        logging.info("%s: Creating metric spec", repr(monitored_model))
        # Add monitoring model to the monitored model
        metric_config = MetricSpecConfig(monitoring_model.id,
                                         outlier_detector.threshold_,
                                         TresholdCmpOp.LESS)
        MetricSpec.create(hs_cluster, "auto_od_metric", monitored_model.id, metric_config)
    except Exception as e:
        logging.exception("%s: Error while MetricSpec creating", repr(monitored_model))
        db.model_statuses.update_one({'monitored_model_version_id': monitored_model_version_id},
                                     {"$set": {'state': AutoODMethodStatuses.FAILED.name,
                                               'description': f"Failed to attach deployed monitoring model as a metric - {str(e)}"}})
        return -1

    db.model_statuses.update_one({'monitored_model_version_id': monitored_model_version_id},
                                 {"$set": {'state': AutoODMethodStatuses.SUCCESS.name, 'description': "😃"}})

    logging.info("%s: Done", repr(monitored_model))
    return 1


if __name__ == "__main__":
    if not DEBUG_ENV:
        serve(app, host='0.0.0.0', port=5000)
    else:
        app.run(debug=True, host='0.0.0.0', port=5000)
